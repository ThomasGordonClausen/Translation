{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Bidirectional + 3 GRU layers + 1024 latent dim\n",
    "- Bidirectional + 3 GRU layers\n",
    "\n",
    "**Reference, best result so far:**\n",
    "\n",
    "**Conclusions:**\n",
    "- sort of the same, forward or backward makes no big difference\n",
    "- Bidirectional is clearly better (loss)\n",
    "- 3 GRU layes does not make it better ...\n",
    "\n",
    "Testing setup:               | Loss achieved                   | Speed         \n",
    "---|---|---|\n",
    "backward                     | loss: 1.3475 - val_loss: 1.7949 | 111 sec/epoch \n",
    "forward                      | loss: 1.3751 - val_loss: 1.8150 | 111 sec/epoch \n",
    "go_backwards parameter       | loss: 1.3947 - val_loss: 1.8325 | 111 sec/epoch \n",
    "bidirectional                | loss: 1.2247 - val_loss: 1.7828 | 185 sec/epoch \n",
    "bidir and latent_dim=1024    | loss: 0.8803 - val_loss: 1.7386 | 412 sec/epoch \n",
    "bidir and 3 GRU              | loss: 1.3554 - val_loss: 1.8040 | 216 sec/epoch \n",
    "bidir and 3 GRU and 1024 lat | loss: 1.2439 - val_loss: 1.8546 | 544 sec/epoch \n",
    "\n",
    "**Improvments to be implemented:**\n",
    "- **Done** Reverse input string?\n",
    "- \"go_backwards\" input to layer to test if it works like backwards?\n",
    "- Indrease size of vocabulary, different for the two languages?\n",
    "- More GRU layers?\n",
    "- Bidirectional GRU layers\n",
    "- **Done** Change Embedding size\n",
    "- Try LSTM instead\n",
    "- **Done** Larger latent_dim for GRU (=512?)\n",
    "- try / understand 'TimeDistributed': decoder_dense = TimeDistributed(Dense(Y_lstm.shape[2], activation = 'relu'))\n",
    "- dropout as layer\n",
    "- L2 reg\n",
    "- bi-directional layers: https://stackoverflow.com/questions/50815354/seq2seq-bidirectional-encoder-decoder-in-keras or https://www.programcreek.com/python/example/92259/keras.layers.wrappers.Bidirectional\n",
    "- attention \n",
    "- Gradient clipping is important for RNNs training (clipvalue=1.0), book page 309\n",
    "- **Done** deeper models to represent more complex sentences, more RNN layers?\n",
    "- **Done** clean-up code around the internal states, lots of confusion around \"[]\"\n",
    "- **Done** Smaller batch size, eg 32 vs 512 may give a getter val_loss? Proved to be that way with the chatbot!\n",
    "- **Done** test Pandas dataframe for nice outputs (https://www.tutorialspoint.com/python_pandas/python_pandas_dataframe.htm)\n",
    "- **Done** dropout in RNN layer:\n",
    "- **Done** Simplify by suing GRU RNN\n",
    "- **Done** ' to_categorical' as one-hot encoder, makes huge matrices\n",
    "- **Done** \"sparse_categorical_crossentropy\" to reduce the 'one hot' tensor\n",
    "- **Done** operates right now with long sentences: 8*std_div, shound be less when longer sentences are trained\n",
    "- **Done** train on larger dataset\n",
    "- **Done** something is wrong with the index of the one-hot; the model allows to return \"0\" as the best index, but the token2word starts from \"1\". It seems to be OK\n",
    "- **Done** remove num_samples\n",
    "\n",
    "**Credits to many fine people on the internet:**\n",
    "- https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "- https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7\n",
    "- https://stackoverflow.com/questions/49477097/keras-seq2seq-word-embedding\n",
    "- https://github.com/devm2024/nmt_keras/blob/master/base.ipynb\n",
    "- https://www.kaggle.com/ievgenvp/lstm-encoder-decoder-via-keras-lb-0-5\n",
    "- https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThomasGordon\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, GRU, Dense, Bidirectional, Concatenate\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "num_words_inp = 10000      # Limit vocabulary in translation for input language\n",
    "num_words_out = 10000      # Limit vocabulary in translation for output language\n",
    "latent_dim = 1024          # Latent dimensionality of the encoding space\n",
    "\n",
    "batch_size = 256           # Batch size for training (Hvass uses 640=512+128)\n",
    "numEpochs = 10             # Number of epochs to train for\n",
    "DropOut = 0.3              # Used in GRU layers\n",
    "\n",
    "dataSetSize = 100000       # small dataset = 14839, all data = 9999999\n",
    "\n",
    "truncate_std_div = 2       # truncate sentences after x tokens, 2 standard deviations = 95% included\n",
    "mark_start = 'ssss '       # start and end markes for destination sentences\n",
    "mark_end = ' eeee'\n",
    "\n",
    "idx = 1000                 # index to be used as demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize traing data\n",
    "### Read training data into tables\n",
    "The result is two tables with the input and output texts: **input_texts[]** and **output_texts[]**. Output texts are enriched by adding the start and end markers. I join sentences from two datasets to get a larger and more diverse training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of small dataset:  14839\n",
      "['Aldrig i livet!', 'Ikke tale om!', 'Absolut ikke!', 'Under ingen omstændigheder!', 'Aldrig i verden!']\n",
      "['ssss No way! eeee', 'ssss No way! eeee', 'ssss No way! eeee', 'ssss No way! eeee', 'ssss No way! eeee']\n"
     ]
    }
   ],
   "source": [
    "# Read data into tables, first data set, the small data set\n",
    "input_texts_a = []\n",
    "target_texts_a = []\n",
    "\n",
    "with open('dan-eng/dan.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[:len(lines)-1]:\n",
    "    target_sentence, input_sentence = line.split('\\t')                   # reversed to get DA --> EN\n",
    "    target_sentence = mark_start + target_sentence.strip() + mark_end\n",
    "    input_texts_a.append(input_sentence)\n",
    "    target_texts_a.append(target_sentence)\n",
    "\n",
    "# Examples\n",
    "print('Size of small dataset: ', len(input_texts_a))\n",
    "print(input_texts_a[15:20])\n",
    "print(target_texts_a[15:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source into a table, the second and larger dataset\n",
    "filename = \"europarl-v7.da-en.da\"\n",
    "data_dir = \"data/europarl/\"\n",
    "path = os.path.join(data_dir, filename)\n",
    "with open(path, encoding=\"utf-8\") as file:\n",
    "    # Read the line from file, strip leading and trailing whitespace,\n",
    "    # prepend the start-text and append the end-text.\n",
    "    input_texts = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination into a table, the second and larger dataset\n",
    "filename = \"europarl-v7.da-en.en\"\n",
    "path = os.path.join(data_dir, filename)\n",
    "with open(path, encoding=\"utf-8\") as file:\n",
    "    # Read the line from file, strip leading and trailing whitespace,\n",
    "    # prepend the start-text and append the end-text.\n",
    "    target_texts = [mark_start + line.strip() + mark_end for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of large dataset:  1968800\n",
      "Selvom markedet siden tidernes morgen har været menneskets privilegerede arena for handel, har det aldrig været perfekt.\n",
      "ssss While, since the dawn of time, the market has been the key forum for human interchange, it has never been perfect. eeee\n"
     ]
    }
   ],
   "source": [
    "print('Size of large dataset: ', len(input_texts))\n",
    "print(input_texts[idx])\n",
    "print(target_texts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of small+large dataset:  1983639\n"
     ]
    }
   ],
   "source": [
    "# join the two data set to one big, gives me both short and long sentences\n",
    "input_texts = input_texts_a + input_texts\n",
    "target_texts = target_texts_a + target_texts\n",
    "print('Size of small+large dataset: ', len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size:    1983639 1983639\n",
      "New lighter dataset size: 100000 100000\n"
     ]
    }
   ],
   "source": [
    "# shorten data sets to speed up training for easy experimentation\n",
    "print\n",
    "print('Original dataset size:   ', len(input_texts), len(target_texts))\n",
    "input_texts = input_texts[:dataSetSize]\n",
    "target_texts = target_texts[:dataSetSize]\n",
    "print('New lighter dataset size:', len(input_texts), len(target_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source texts</th>\n",
       "      <th>Target texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49132</th>\n",
       "      <td>Det er vigtigt, at det finansielle ansvar for flygtninge fordeles mellem medlemsstaterne.</td>\n",
       "      <td>ssss It is important that the financial responsibility for refugees be distributed among Member States. eeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37184</th>\n",
       "      <td>Betingelserne for et bedre liv, beskæftigelse og kvaliteten af denne vil altid være tæt forbundne med vores evne til at skabe dynamik i EU's forskning.</td>\n",
       "      <td>ssss Improved living conditions, employment and the quality of employment will continue to be intimately linked to our ability to make European research more dynamic. eeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94102</th>\n",
       "      <td>I øvrigt har Rådet frigjort en sikkerhedsmargen på 208 millioner euro over beløbet i Kommissionens udkast til budgetforslag med det formål at råde over en tilstrækkelig manøvremargen ud over den nødvendige margen under loftet for rubrik 3 for at kunne imødegå de nye prioriteringer, som Rådet og Parlamentet er enige om, såsom initiativet \"Beskæftigelse\", som jeg netop har omtalt.</td>\n",
       "      <td>ssss Furthermore, it has identified a precautionary margin of EUR 208 million more than the one in the Commission' s preliminary draft budget, the objective being to have enough room for manoeuvre over and above a necessary margin under the ceiling of category 3 to deal with the new priorities shared by the Council and by Parliament, such as the 'employment' initiative I mentioned earlier. eeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97554</th>\n",
       "      <td>Derfor har Kommissionen i sinde at afslå samfinansiering af den udbetalte støtte med tilbagevirkende kraft fra 1. august 1996.</td>\n",
       "      <td>ssss The Commission will therefore refuse to co-finance grants paid out, backdated to 1 August 1996. eeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59371</th>\n",
       "      <td>Fru van der Laan, jeg forstår, at De anmoder om et beslutningsdygtigt flertal.</td>\n",
       "      <td>ssss Mrs Van der Laan, I understand that you would like the quorum to be checked. eeee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                        Source texts  \\\n",
       "49132  Det er vigtigt, at det finansielle ansvar for flygtninge fordeles mellem medlemsstaterne.                                                                                                                                                                                                                                                                                                       \n",
       "37184  Betingelserne for et bedre liv, beskæftigelse og kvaliteten af denne vil altid være tæt forbundne med vores evne til at skabe dynamik i EU's forskning.                                                                                                                                                                                                                                         \n",
       "94102  I øvrigt har Rådet frigjort en sikkerhedsmargen på 208 millioner euro over beløbet i Kommissionens udkast til budgetforslag med det formål at råde over en tilstrækkelig manøvremargen ud over den nødvendige margen under loftet for rubrik 3 for at kunne imødegå de nye prioriteringer, som Rådet og Parlamentet er enige om, såsom initiativet \"Beskæftigelse\", som jeg netop har omtalt.   \n",
       "97554  Derfor har Kommissionen i sinde at afslå samfinansiering af den udbetalte støtte med tilbagevirkende kraft fra 1. august 1996.                                                                                                                                                                                                                                                                  \n",
       "59371  Fru van der Laan, jeg forstår, at De anmoder om et beslutningsdygtigt flertal.                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                        Target texts  \n",
       "49132  ssss It is important that the financial responsibility for refugees be distributed among Member States. eeee                                                                                                                                                                                                                                                                                                   \n",
       "37184  ssss Improved living conditions, employment and the quality of employment will continue to be intimately linked to our ability to make European research more dynamic. eeee                                                                                                                                                                                                                                    \n",
       "94102  ssss Furthermore, it has identified a precautionary margin of EUR 208 million more than the one in the Commission' s preliminary draft budget, the objective being to have enough room for manoeuvre over and above a necessary margin under the ceiling of category 3 to deal with the new priorities shared by the Council and by Parliament, such as the 'employment' initiative I mentioned earlier. eeee  \n",
       "97554  ssss The Commission will therefore refuse to co-finance grants paid out, backdated to 1 August 1996. eeee                                                                                                                                                                                                                                                                                                      \n",
       "59371  ssss Mrs Van der Laan, I understand that you would like the quorum to be checked. eeee                                                                                                                                                                                                                                                                                                                         "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing Pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df = pd.DataFrame({'Source texts':input_texts, 'Target texts':target_texts})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize input sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58607 unique source tokens.\n",
      "Longest sentence is 206 tokens.\n",
      "Sentences shortened to max 47 tokens.\n",
      "Shape of input tokens: (100000, 47)\n",
      "Input example:\n",
      "[  10 2281    5    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "de købte det\n",
      "De købte det.\n"
     ]
    }
   ],
   "source": [
    "# crate input tokenizer and create vocabulary from the texts\n",
    "tokenizer_inp = Tokenizer(num_words=num_words_inp)\n",
    "tokenizer_inp.fit_on_texts(input_texts)\n",
    "print('Found %s unique source tokens.' % len(tokenizer_inp.word_index))\n",
    "\n",
    "# translate from word sentences to token sentences\n",
    "tokens_inp = tokenizer_inp.texts_to_sequences(input_texts)\n",
    "\n",
    "# Reverse the token-sequences\n",
    "#tokens_inp = [list(reversed(x)) for x in tokens_inp]\n",
    "\n",
    "# Shorten the longest token sentences, Find the length of all sentences, truncate after x * std deviations\n",
    "num_tokens = [len(x) for x in tokens_inp]\n",
    "print('Longest sentence is %s tokens.' % max(num_tokens))\n",
    "max_tokens_input = np.mean(num_tokens) + truncate_std_div * np.std(num_tokens)\n",
    "max_tokens_input = min(int(max_tokens_input), max(num_tokens))\n",
    "print('Sentences shortened to max %s tokens.' % max_tokens_input)\n",
    "\n",
    "# Pad / truncate all token-sequences to the given length\n",
    "tokens_padded_input = pad_sequences(tokens_inp,\n",
    "                                    maxlen=max_tokens_input,\n",
    "                                    padding='post',\n",
    "                                    truncating='post')\n",
    "\n",
    "# Create inverse lookup from integer-tokens to words\n",
    "index_to_word_input = dict(zip(tokenizer_inp.word_index.values(), tokenizer_inp.word_index.keys()))\n",
    "\n",
    "# function to return readable text from tokens string\n",
    "def tokens_to_string_inp(tokens):\n",
    "    words = [index_to_word_input[token] \n",
    "            for token in tokens\n",
    "            if token != 0]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "# demo to show that it works\n",
    "print('Shape of input tokens:', tokens_padded_input.shape)\n",
    "print('Input example:')\n",
    "print(tokens_padded_input[idx])\n",
    "print(tokens_to_string_inp(tokens_padded_input[idx]))\n",
    "print(input_texts[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize destination sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28740 unique target tokens.\n",
      "Longest sentence is 258 tokens.\n",
      "Sentences shortened to max 55 tokens.\n",
      "Shape of target tokens: (100000, 55)\n",
      "Target example:\n",
      "[   2   54 1625   16    3    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "ssss they bought it eeee\n",
      "ssss They bought it. eeee\n"
     ]
    }
   ],
   "source": [
    "# crate input tokenizer and create vocabulary from the texts\n",
    "tokenizer_target = Tokenizer(num_words=num_words_out)\n",
    "tokenizer_target.fit_on_texts(target_texts)\n",
    "print('Found %s unique target tokens.' % len(tokenizer_target.word_index))\n",
    "\n",
    "# translate from word sentences to token sentences\n",
    "tokens_target = tokenizer_target.texts_to_sequences(target_texts)\n",
    "\n",
    "# translate from word sentences to token sentences\n",
    "tokens_target = tokenizer_target.texts_to_sequences(target_texts)\n",
    "\n",
    "# Shorten the longest token sentences, Find the length of all sentences, truncate after x * std deviations\n",
    "num_tokens = [len(x) for x in tokens_target]\n",
    "print('Longest sentence is %s tokens.' % max(num_tokens))\n",
    "max_tokens_target = np.mean(num_tokens) + truncate_std_div * np.std(num_tokens)\n",
    "max_tokens_target = min(int(max_tokens_target), max(num_tokens))\n",
    "print('Sentences shortened to max %s tokens.' % max_tokens_target)\n",
    "\n",
    "# Pad / truncate all token-sequences to the given length\n",
    "tokens_padded_target = pad_sequences(tokens_target,\n",
    "                                     maxlen=max_tokens_target,\n",
    "                                     padding='post',\n",
    "                                    truncating='post')\n",
    "\n",
    "# Create inverse lookup from integer-tokens to words\n",
    "index_to_word_target = dict(zip(tokenizer_target.word_index.values(), tokenizer_target.word_index.keys()))\n",
    "\n",
    "# function to return readable text from tokens string\n",
    "def tokens_to_string_target(tokens):\n",
    "    words = [index_to_word_target[token] \n",
    "            for token in tokens\n",
    "            if token != 0]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "# demo to show that it works\n",
    "print('Shape of target tokens:', tokens_padded_target.shape)\n",
    "print('Target example:')\n",
    "print(tokens_padded_target[idx])\n",
    "print(tokens_to_string_target(tokens_padded_target[idx]))\n",
    "print(target_texts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "# start and end marks as tokens, needed when translating\n",
    "token_start = tokenizer_target.word_index[mark_start.strip()]\n",
    "token_end = tokenizer_target.word_index[mark_end.strip()]\n",
    "print(token_start, token_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traing data\n",
    "- Input to the encoder is simply the source language as it is\n",
    "- Inputs to the decoder are slightly more complicated, since the two input strings are shiften one time-step: The model has to learn to predict the \"next\" token in the output from the input. Slizing is used to get two \"views\" to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 47)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data = tokens_padded_input\n",
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 54)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data = tokens_padded_target[:, :-1]\n",
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 54)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data = tokens_padded_target[:, 1:]\n",
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples showing the training data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10, 2281,    5,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,   54, 1625,   16,    3,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  54, 1625,   16,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models\n",
    "\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU encoder elements\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
    "encoder_embed = Embedding(num_words_inp, latent_dim, name='encoder_embedding')\n",
    "\n",
    "\n",
    "encoder_GRU0 = Bidirectional(\n",
    "                    GRU(latent_dim, \n",
    "                        dropout=DropOut, \n",
    "                        recurrent_dropout=DropOut, \n",
    "                        return_sequences=True,\n",
    "                        return_state=False, \n",
    "                        name='encoder_gru0'))\n",
    "\n",
    "encoder_GRU1 = GRU(latent_dim, \n",
    "                   dropout=DropOut, \n",
    "                   recurrent_dropout=DropOut, \n",
    "                   return_sequences=True,\n",
    "                   return_state=False, \n",
    "                   name='encoder_gru1')\n",
    "\n",
    "encoder_GRU2 = GRU(latent_dim, \n",
    "                   dropout=DropOut, \n",
    "                   recurrent_dropout=DropOut, \n",
    "                   return_sequences=False, \n",
    "                   return_state=True, \n",
    "                   name='encoder_gru2')\n",
    "\n",
    "# connect encoder\n",
    "net = encoder_inputs\n",
    "net = encoder_embed(net)\n",
    "net = encoder_GRU0(net)\n",
    "net = encoder_GRU1(net)\n",
    "net = encoder_GRU2(net)\n",
    "\n",
    "# outputs of encoder, from last GRU layer\n",
    "encoder_outputs, state_h = net\n",
    "\n",
    "# encoder model used to create internal representation / states\n",
    "encoder_model = Model(encoder_inputs, state_h)\n",
    "#encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU decoder elements, using `state_h` (encoder hidden states) as initial state\n",
    "decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
    "decoder_embed =  Embedding(num_words_out, latent_dim, name='decoder_embedding')\n",
    "decoder_gru1 =   GRU(latent_dim, \n",
    "                     dropout=DropOut, recurrent_dropout=DropOut, \n",
    "                     return_sequences=True, \n",
    "                     return_state=False, \n",
    "                     name='decoder_gru1')    \n",
    "decoder_gru2 =   GRU(latent_dim, \n",
    "                     dropout=DropOut, recurrent_dropout=DropOut, \n",
    "                     return_sequences=True, \n",
    "                     return_state=False, \n",
    "                     name='decoder_gru2')    \n",
    "decoder_gru3 =   GRU(latent_dim, \n",
    "                     dropout=DropOut, recurrent_dropout=DropOut, \n",
    "                     return_sequences=True, \n",
    "                     return_state=True, \n",
    "                     name='decoder_gru3')    \n",
    "decoder_dense =  Dense(num_words_out, activation='linear', name='decoder_output')\n",
    "\n",
    "# connect decoder\n",
    "net = decoder_inputs\n",
    "net = decoder_embed(net)\n",
    "#net = decoder_gru1(net, initial_state=state_h)\n",
    "#net = decoder_gru2(net, initial_state=state_h)\n",
    "net = decoder_gru3(net, initial_state=state_h)\n",
    "\n",
    "# connect dense layer to GRUs\n",
    "decoder_outputs, dec_states_h = net\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# define decoder model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder inital state is an internal state\n",
    "decoder_initial_state = Input(shape=(latent_dim,),\n",
    "                              name='decoder_initial_state')\n",
    "\n",
    "# connect decoder\n",
    "net = decoder_inputs\n",
    "net = decoder_embed(net)\n",
    "#net = decoder_gru1(net, initial_state=decoder_initial_state)\n",
    "#net = decoder_gru2(net, initial_state=decoder_initial_state)\n",
    "net = decoder_gru3(net, initial_state=decoder_initial_state)\n",
    "\n",
    "# connect dense layer to GRUs\n",
    "decoder_outputs, dec_states_h = net\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# connect inference decoder model\n",
    "decoder_model = Model([decoder_inputs]+[decoder_initial_state], \n",
    "                      [decoder_outputs]+[dec_states_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the traing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"553pt\" viewBox=\"0.00 0.00 838.50 553.00\" width=\"839pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-549 834.5,-549 834.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2157725887120 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2157725887120</title>\n",
       "<polygon fill=\"none\" points=\"86,-498.5 86,-544.5 399,-544.5 399,-498.5 86,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-517.8\">encoder_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"250,-498.5 250,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"250,-521.5 306,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"306,-498.5 306,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"352.5\" y=\"-529.3\">(None, None)</text>\n",
       "<polyline fill=\"none\" points=\"306,-521.5 399,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"352.5\" y=\"-506.3\">(None, None)</text>\n",
       "</g>\n",
       "<!-- 2157725887960 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2157725887960</title>\n",
       "<polygon fill=\"none\" points=\"50,-415.5 50,-461.5 435,-461.5 435,-415.5 50,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150.5\" y=\"-434.8\">encoder_embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"251,-415.5 251,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"251,-438.5 307,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"307,-415.5 307,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371\" y=\"-446.3\">(None, None)</text>\n",
       "<polyline fill=\"none\" points=\"307,-438.5 435,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371\" y=\"-423.3\">(None, None, 1024)</text>\n",
       "</g>\n",
       "<!-- 2157725887120&#45;&gt;2157725887960 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2157725887120-&gt;2157725887960</title>\n",
       "<path d=\"M242.5,-498.366C242.5,-490.152 242.5,-480.658 242.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246,-471.607 242.5,-461.607 239,-471.607 246,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157725885104 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2157725885104</title>\n",
       "<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 485,-378.5 485,-332.5 0,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150.5\" y=\"-351.8\">bidirectional_1(encoder_gru0): Bidirectional(GRU)</text>\n",
       "<polyline fill=\"none\" points=\"301,-332.5 301,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"301,-355.5 357,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"357,-332.5 357,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-363.3\">(None, None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"357,-355.5 485,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-340.3\">(None, None, 2048)</text>\n",
       "</g>\n",
       "<!-- 2157725887960&#45;&gt;2157725885104 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2157725887960-&gt;2157725885104</title>\n",
       "<path d=\"M242.5,-415.366C242.5,-407.152 242.5,-397.658 242.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246,-388.607 242.5,-378.607 239,-388.607 246,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157725829328 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2157725829328</title>\n",
       "<polygon fill=\"none\" points=\"85,-249.5 85,-295.5 400,-295.5 400,-249.5 85,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150.5\" y=\"-268.8\">encoder_gru1: GRU</text>\n",
       "<polyline fill=\"none\" points=\"216,-249.5 216,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"216,-272.5 272,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"272,-249.5 272,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336\" y=\"-280.3\">(None, None, 2048)</text>\n",
       "<polyline fill=\"none\" points=\"272,-272.5 400,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336\" y=\"-257.3\">(None, None, 1024)</text>\n",
       "</g>\n",
       "<!-- 2157725885104&#45;&gt;2157725829328 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2157725885104-&gt;2157725829328</title>\n",
       "<path d=\"M242.5,-332.366C242.5,-324.152 242.5,-314.658 242.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246,-305.607 242.5,-295.607 239,-305.607 246,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157341947384 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2157341947384</title>\n",
       "<polygon fill=\"none\" points=\"480.5,-249.5 480.5,-295.5 794.5,-295.5 794.5,-249.5 480.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"563\" y=\"-268.8\">decoder_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-249.5 645.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-272.5 701.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"701.5,-249.5 701.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"748\" y=\"-280.3\">(None, None)</text>\n",
       "<polyline fill=\"none\" points=\"701.5,-272.5 794.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"748\" y=\"-257.3\">(None, None)</text>\n",
       "</g>\n",
       "<!-- 2157341947048 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2157341947048</title>\n",
       "<polygon fill=\"none\" points=\"444.5,-166.5 444.5,-212.5 830.5,-212.5 830.5,-166.5 444.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"545.5\" y=\"-185.8\">decoder_embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"646.5,-166.5 646.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"646.5,-189.5 702.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"702.5,-166.5 702.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"766.5\" y=\"-197.3\">(None, None)</text>\n",
       "<polyline fill=\"none\" points=\"702.5,-189.5 830.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"766.5\" y=\"-174.3\">(None, None, 1024)</text>\n",
       "</g>\n",
       "<!-- 2157341947384&#45;&gt;2157341947048 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2157341947384-&gt;2157341947048</title>\n",
       "<path d=\"M637.5,-249.366C637.5,-241.152 637.5,-231.658 637.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"641,-222.607 637.5,-212.607 634,-222.607 641,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157725885552 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2157725885552</title>\n",
       "<polygon fill=\"none\" points=\"59,-166.5 59,-212.5 426,-212.5 426,-166.5 59,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"124.5\" y=\"-185.8\">encoder_gru2: GRU</text>\n",
       "<polyline fill=\"none\" points=\"190,-166.5 190,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"190,-189.5 246,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"246,-166.5 246,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336\" y=\"-197.3\">(None, None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"246,-189.5 426,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336\" y=\"-174.3\">[(None, 1024), (None, 1024)]</text>\n",
       "</g>\n",
       "<!-- 2157725829328&#45;&gt;2157725885552 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2157725829328-&gt;2157725885552</title>\n",
       "<path d=\"M242.5,-249.366C242.5,-241.152 242.5,-231.658 242.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246,-222.607 242.5,-212.607 239,-222.607 246,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157341948728 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2157341948728</title>\n",
       "<polygon fill=\"none\" points=\"237,-83.5 237,-129.5 642,-129.5 642,-83.5 237,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-102.8\">decoder_gru3: GRU</text>\n",
       "<polyline fill=\"none\" points=\"368,-83.5 368,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"368,-106.5 424,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"424,-83.5 424,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"533\" y=\"-114.3\">[(None, None, 1024), (None, 1024)]</text>\n",
       "<polyline fill=\"none\" points=\"424,-106.5 642,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"533\" y=\"-91.3\">[(None, None, 1024), (None, 1024)]</text>\n",
       "</g>\n",
       "<!-- 2157341947048&#45;&gt;2157341948728 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2157341947048-&gt;2157341948728</title>\n",
       "<path d=\"M583.657,-166.473C558.67,-156.251 528.797,-144.031 502.742,-133.372\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"503.913,-130.069 493.332,-129.522 501.262,-136.548 503.913,-130.069\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157725885552&#45;&gt;2157341948728 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2157725885552-&gt;2157341948728</title>\n",
       "<path d=\"M296.071,-166.473C320.932,-156.251 350.654,-144.031 376.577,-133.372\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"378.022,-136.562 385.94,-129.522 375.36,-130.088 378.022,-136.562\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157341949288 -->\n",
       "<g class=\"node\" id=\"node9\"><title>2157341949288</title>\n",
       "<polygon fill=\"none\" points=\"271,-0.5 271,-46.5 608,-46.5 608,-0.5 271,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344.5\" y=\"-19.8\">decoder_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"418,-0.5 418,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"418,-23.5 474,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"474,-0.5 474,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"541\" y=\"-31.3\">(None, None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"474,-23.5 608,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"541\" y=\"-8.3\">(None, None, 10000)</text>\n",
       "</g>\n",
       "<!-- 2157341948728&#45;&gt;2157341949288 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2157341948728-&gt;2157341949288</title>\n",
       "<path d=\"M439.5,-83.3664C439.5,-75.1516 439.5,-65.6579 439.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"443,-56.6068 439.5,-46.6068 436,-56.6069 443,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise model as a graph\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import pydot_ng as pydot\n",
    "import graphviz as graphviz\n",
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 757.50 304.00\" width=\"758pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 753.5,-300 753.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2157341947384 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2157341947384</title>\n",
       "<polygon fill=\"none\" points=\"36,-249.5 36,-295.5 350,-295.5 350,-249.5 36,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-268.8\">decoder_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"201,-249.5 201,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"201,-272.5 257,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"257,-249.5 257,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-280.3\">(None, None)</text>\n",
       "<polyline fill=\"none\" points=\"257,-272.5 350,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-257.3\">(None, None)</text>\n",
       "</g>\n",
       "<!-- 2157341947048 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2157341947048</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 386,-212.5 386,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-185.8\">decoder_embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"202,-166.5 202,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"202,-189.5 258,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"258,-166.5 258,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-197.3\">(None, None)</text>\n",
       "<polyline fill=\"none\" points=\"258,-189.5 386,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-174.3\">(None, None, 1024)</text>\n",
       "</g>\n",
       "<!-- 2157341947384&#45;&gt;2157341947048 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2157341947384-&gt;2157341947048</title>\n",
       "<path d=\"M193,-249.366C193,-241.152 193,-231.658 193,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"196.5,-222.607 193,-212.607 189.5,-222.607 196.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157341948728 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2157341948728</title>\n",
       "<polygon fill=\"none\" points=\"182.5,-83.5 182.5,-129.5 587.5,-129.5 587.5,-83.5 182.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-102.8\">decoder_gru3: GRU</text>\n",
       "<polyline fill=\"none\" points=\"313.5,-83.5 313.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"313.5,-106.5 369.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"369.5,-83.5 369.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"478.5\" y=\"-114.3\">[(None, None, 1024), (None, 1024)]</text>\n",
       "<polyline fill=\"none\" points=\"369.5,-106.5 587.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"478.5\" y=\"-91.3\">[(None, None, 1024), (None, 1024)]</text>\n",
       "</g>\n",
       "<!-- 2157341947048&#45;&gt;2157341948728 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2157341947048-&gt;2157341948728</title>\n",
       "<path d=\"M245.211,-166.473C269.335,-156.296 298.155,-144.138 323.341,-133.512\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"324.946,-136.634 332.799,-129.522 322.225,-130.185 324.946,-136.634\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157684950016 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2157684950016</title>\n",
       "<polygon fill=\"none\" points=\"404.5,-166.5 404.5,-212.5 749.5,-212.5 749.5,-166.5 404.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-185.8\">decoder_initial_state: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"603.5,-166.5 603.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"631.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"603.5,-189.5 659.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"631.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"659.5,-166.5 659.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-197.3\">(None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"659.5,-189.5 749.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-174.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 2157684950016&#45;&gt;2157341948728 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2157684950016-&gt;2157341948728</title>\n",
       "<path d=\"M524.789,-166.473C500.665,-156.296 471.845,-144.138 446.659,-133.512\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"447.775,-130.185 437.201,-129.522 445.054,-136.634 447.775,-130.185\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2157341949288 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2157341949288</title>\n",
       "<polygon fill=\"none\" points=\"216.5,-0.5 216.5,-46.5 553.5,-46.5 553.5,-0.5 216.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290\" y=\"-19.8\">decoder_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"363.5,-0.5 363.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"363.5,-23.5 419.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"419.5,-0.5 419.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"486.5\" y=\"-31.3\">(None, None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"419.5,-23.5 553.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"486.5\" y=\"-8.3\">(None, None, 10000)</text>\n",
       "</g>\n",
       "<!-- 2157341948728&#45;&gt;2157341949288 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2157341948728-&gt;2157341949288</title>\n",
       "<path d=\"M385,-83.3664C385,-75.1516 385,-65.6579 385,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"388.5,-56.6068 385,-46.6068 381.5,-56.6069 388.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise encoder model as a graph\n",
    "SVG(model_to_dot(decoder_model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function since sparse does not work: https://github.com/tensorflow/tensorflow/issues/17150\n",
    "def sparse_cross_entropy(y_true, y_pred):\n",
    "    # Calculate the loss. This outputs a 2-rank tensor of shape [batch_size, sequence_length]\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target = tf.placeholder(dtype='int32', shape=(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=sparse_cross_entropy,\n",
    "              target_tensors=[decoder_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call backs to stop model when it does not improve more\n",
    "path_checkpoint = 'tgc_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                        patience=3, \n",
    "                                        verbose=1)\n",
    "\n",
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load check-point if it exists (contunie training)\n",
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 551s 7ms/step - loss: 2.3117 - val_loss: 2.2769\n",
      "Epoch 00001: val_loss improved from inf to 2.27689, saving model to tgc_checkpoint.keras\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 541s 7ms/step - loss: 1.8205 - val_loss: 2.1049\n",
      "Epoch 00002: val_loss improved from 2.27689 to 2.10493, saving model to tgc_checkpoint.keras\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 544s 7ms/step - loss: 1.6818 - val_loss: 2.0245\n",
      "Epoch 00003: val_loss improved from 2.10493 to 2.02455, saving model to tgc_checkpoint.keras\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 543s 7ms/step - loss: 1.5853 - val_loss: 1.9656\n",
      "Epoch 00004: val_loss improved from 2.02455 to 1.96562, saving model to tgc_checkpoint.keras\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 543s 7ms/step - loss: 1.5088 - val_loss: 1.9301\n",
      "Epoch 00005: val_loss improved from 1.96562 to 1.93008, saving model to tgc_checkpoint.keras\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 543s 7ms/step - loss: 1.4427 - val_loss: 1.9059\n",
      "Epoch 00006: val_loss improved from 1.93008 to 1.90587, saving model to tgc_checkpoint.keras\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 541s 7ms/step - loss: 1.3843 - val_loss: 1.8831\n",
      "Epoch 00007: val_loss improved from 1.90587 to 1.88308, saving model to tgc_checkpoint.keras\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 539s 7ms/step - loss: 1.3321 - val_loss: 1.8683\n",
      "Epoch 00008: val_loss improved from 1.88308 to 1.86832, saving model to tgc_checkpoint.keras\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 541s 7ms/step - loss: 1.2854 - val_loss: 1.8596\n",
      "Epoch 00009: val_loss improved from 1.86832 to 1.85960, saving model to tgc_checkpoint.keras\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 544s 7ms/step - loss: 1.2439 - val_loss: 1.8546\n",
      "Epoch 00010: val_loss improved from 1.85960 to 1.85462, saving model to tgc_checkpoint.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThomasGordon\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:2368: UserWarning: Layer decoder_gru3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_gru2/while/Exit_2:0' shape=(?, 1024) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# Note that `decoder_target_data` needs to be one-hot encoded, rather than sequences of integers like `decoder_input_data`\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=numEpochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)\n",
    "model.save('TGC_trans.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f8015ab710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotter historikken for 'loss'\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')       # bo = \"blue dot\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')  # b  = \"solid blue line\"\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that does the translation\n",
    "def decode_sequence(input_seq):\n",
    "   \n",
    "    # tokenize the text to be translated, and reverse\n",
    "    input_tokens = tokenizer_inp.texts_to_sequences([input_seq])\n",
    "    \n",
    "    # Reverse the token-sequences\n",
    "    #input_tokens = [list(reversed(x)) for x in input_tokens]\n",
    "\n",
    "    # Pad sequence\n",
    "    input_tokens = pad_sequences(input_tokens,\n",
    "                                 maxlen=max_tokens_input,\n",
    "                                 padding='post',\n",
    "                                 truncating='post')\n",
    "\n",
    "    # encode the input sentence\n",
    "    states_value = encoder_model.predict(input_tokens)\n",
    "    \n",
    "    # Generate empty target sequence of length 1 and insert start token\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = token_start    #\n",
    "\n",
    "    # sampling loop to generate translated words using decoder, word by word\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:  \n",
    "        # predict one next word, decoder returns probabilities for all words/tokens\n",
    "        output_tokens, h = decoder_model.predict([target_seq] + [states_value])\n",
    "        \n",
    "        # pick most probable token / word. Result '0' is a fault, 0 is reserved to tokenizer\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        if sampled_token_index>0:\n",
    "            sampled_word = index_to_word_target[sampled_token_index]\n",
    "        else:\n",
    "            sampled_word = 'eeee'\n",
    "        \n",
    "        # append most probable word to sentende\n",
    "        decoded_sentence += ' '+sampled_word\n",
    "        \n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_word == 'eeee' or len(decoded_sentence) > 222):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states, so they can be re-injected in next token/word prediction\n",
    "        states_value = h\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing translation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De købte det. \n",
      " ==>   they bought it eeee \n",
      "\n",
      "\n",
      "De købte den. \n",
      " ==>   they bought it eeee \n",
      "\n",
      "\n",
      "De skændtes. \n",
      " ==>   they eeee \n",
      "\n",
      "\n",
      "De vil have mere. \n",
      " ==>   they want to be eeee \n",
      "\n",
      "\n",
      "De var mine. \n",
      " ==>   they were my friend eeee \n",
      "\n",
      "\n",
      "De er idioter. \n",
      " ==>   they're eeee \n",
      "\n",
      "\n",
      "Tænk over det. \n",
      " ==>   think about it eeee \n",
      "\n",
      "\n",
      "Det her er kedeligt. \n",
      " ==>   it's this eeee \n",
      "\n",
      "\n",
      "Det er min hund. \n",
      " ==>   it's my dog eeee \n",
      "\n",
      "\n",
      "Vi får se. \n",
      " ==>   we are going to get married eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on known short sentences from training data\n",
    "for idx in range(1000, 1010):\n",
    "    input_seq = input_texts[idx]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Den således ændrede dagsorden godkendtes) \n",
      " ==>   the committee on budgetary control was adopted eeee \n",
      "\n",
      "\n",
      "Sikkerhedsrådgivere for transport af farligt gods \n",
      " ==>   the second pillar of the common agricultural policy eeee \n",
      "\n",
      "\n",
      "Næste punkt på dagsordenen er betænkning (A5-0105/1999) af Koch for Udvalget om Regionalpolitik, Transport og Turisme om Rådets fælles holdning med henblik på vedtagelse af Europa-Parlamentets og Rådets direktiv om minimumseksamenskravene for sikkerhedsrådgivere i forbindelse med transport af farligt gods med jernbane eller ad vej eller indre vandveje (C5-0208/1999 - 1998/0106(COD)). \n",
      " ==>   the next item is the report a5 2000 by mr on behalf of the committee on legal affairs and the internal market on the proposal for a council regulation ec on the conclusion of the trans european conventional rail system com \n",
      "\n",
      "\n",
      "Ærede fru kommissær, ærede formand, kære kolleger, jeg bifalder Rådets fælles holdning om harmonisering af uddannelsen af sikkerhedsrådgivere i forbindelse med transport af farligt gods med jernbane eller ad vej eller indre vandveje uforbeholdent. \n",
      " ==>   commissioner i would like to reiterate my support for the council and the commission for the fact that the council has not yet received any action to ensure that the various projects are implemented eeee \n",
      "\n",
      "\n",
      "For det første skulle vi formelt være aktive for at opfylde kravene i direktiv 96/35/EF, som forpligter medlemsstaterne til at anvende sikkerhedsansvarlige eller sikkerhedsrådgivere og til at organisere uddannelse, kurser og eksaminer for netop disse personer uden at udføre dette eksplicit. \n",
      " ==>   first we must firstly establish the objectives of the treaty of amsterdam and to ensure that the member states have the right to take decisions on the part of the member states and to ensure that the rules of procedure are \n",
      "\n",
      "\n",
      "For det andet opnår vi følgende med dette direktiv: a) øget sikkerhed både ved transport og ved omladning af farligt gods, b) afskaffelse af konkurrenceforvridning som følge af de mest forskelligartede nationale uddannelsesstrukturer og uddannelsesomkostninger og c) etablering af lige muligheder for sikkerhedsrådgivere på det europæiske arbejdsmarked. \n",
      " ==>   secondly we would like to stress the importance of this directive which is the national and regional authorities which have been involved in the implementation of the structural funds regulation and the cohesion fund eeee \n",
      "\n",
      "\n",
      "For det tredje garanterer vi med direktivet, sådan som det foreligger nu som fælles holdning, især da det udelukkende er begrænset til minimumsstandarder, en høj grad af fleksibilitet og begrænset regulering fra Den Europæiske Unions side, og vi bidrager til et stort egetansvar i medlemsstaterne. \n",
      " ==>   thirdly we would like to see the european union as a whole but in the same way as the member states have to ensure that the rules of procedure are respected and that the member states have to ensure that the rules of procedure \n",
      "\n",
      "\n",
      "Alt dette skal hilses særdeles velkomment i overensstemmelse med nærhedsprincippet. \n",
      " ==>   all this should be included in the common position eeee \n",
      "\n",
      "\n",
      "Vores ændringsforslag fra førstebehandlingen anser jeg for at være tilgodeset på en meget tilfredsstillende måde. \n",
      " ==>   our amendment to the effect is that we should be very careful eeee \n",
      "\n",
      "\n",
      "De blev overtaget, gennemført efter hensigten eller bortfaldt, fordi de tilsvarende europæiske bestemmelser ikke blev optaget, f.eks. et sanktionssystem ved krænkelser eller en kompliceret blokdannelse af spørgsmål. \n",
      " ==>   they have been a member of the european parliament because they are not prepared to pay for their own and their own country eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on known long sentences from training data\n",
    "for idx in range(15000, 15010):\n",
    "    input_seq = input_texts[idx]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Når det drejer sig om dødsstraf, er en retsvildfarelse selvfølgelig særligt alvorlig. Vi må ikke glemme, at man i sådanne tilfælde har indrømmet, at der var sket en retsvildfarelse, og det var ikke tilfældigt, at der var tale om personer, som ikke havde råd til dyre advokater. \n",
      " ==>   when it comes to the situation in iraq we have no problem in this area and we should not be discussing this issue today eeee \n",
      "\n",
      "\n",
      "Når også retssystemet fungerer godt i USA, er det efter min mening, fordi advokaterne bliver virkeligt godt betalt, men det bliver de jo af dem, der har råd til det. \n",
      " ==>   when the time comes to the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the issue of the peace process \n",
      "\n",
      "\n",
      "Vi anmoder derfor om, at denne dom bliver omstødt, og vi anmoder om, at Parlamentets formandskab - også i betragtning af det dokument, som adskillige parlamentsmedlemmer har undertegnet i de seneste par dage - skriver direkte til de ansvarlige myndigheder for hurtigst muligt at henlede deres opmærksomhed på dette emne og naturligvis for at bede dem om at afskaffe dødsstraffen i USA, som vi beundrer så kraftigt på mange områder. \n",
      " ==>   we therefore call on the council to consider the issue of the death penalty in the united states and the other institutions in this chamber which is why we have voted in favour of the report on the implementation of the agreements \n",
      "\n",
      "\n",
      "Netop derfor er det så meget mere skandaløst at se, de holder fast ved dette barbariske ritual. \n",
      " ==>   it is therefore very difficult to understand that this is a very serious matter eeee \n",
      "\n",
      "\n",
      "Hærværk i forbindelse med sport \n",
      " ==>   in the meantime eeee \n",
      "\n",
      "\n",
      "Hr. formand, fodbold er en fest. \n",
      " ==>   mr president the is a crime eeee \n",
      "\n",
      "\n",
      "Under det motto har Belgien og Nederlandene i de forløbne uger organiseret Euro 2000. \n",
      " ==>   in the netherlands and belgium has been in the forefront of the common agricultural policy eeee \n",
      "\n",
      "\n",
      "På sportsområdet blev det også en fest, om end måske mindre udtalt for vores italienske venner. \n",
      " ==>   it was also a very sensitive issue which was discussed in the chamber today eeee \n",
      "\n",
      "\n",
      "En fest, der desværre endnu en gang stod i skyggen af den opførsel, som nogle såkaldte fans lagde for dagen. \n",
      " ==>   a number of people were killed in a chamber by the austrian government eeee \n",
      "\n",
      "\n",
      "Især før og efter kampen mellem Tyskland og England var der alvorlige optøjer. \n",
      " ==>   in fact the situation in the horn of africa and the world was very concerned about the fate of the poorest countries eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on unknown sentences from validation data\n",
    "for idx in range(90000, 90010):\n",
    "    input_seq = input_texts[idx]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi ses \n",
      " ==>   see you eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_seq = 'vi ses'\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idag kan man læse i avisen at Danmark er blevet fornuftigt \n",
      " ==>   can the council say that the court of auditors was not amended eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_seq = 'Idag kan man læse i avisen at Danmark er blevet fornuftigt'\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kvinde står frem med anklager mod højesteretkandidat \n",
      " ==>   the ship is stuck in the eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_seq = 'Kvinde står frem med anklager mod højesteretkandidat'\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kvinde står frem med anklager mod højesteret \n",
      " ==>   the ship is stuck in the eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_seq = 'Kvinde står frem med anklager mod højesteret'\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Han har kategorisk afvist anklagerne \n",
      " ==>   he has made a mistake eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_seq = 'Han har kategorisk afvist anklagerne'\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danmark er et dejligt land \n",
      " ==>   greece is a country eeee \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_seq = 'Danmark er et dejligt land'\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(input_seq, '\\n ==> ', decoded_sentence, '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
